{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sphinx thinks you said \n",
      "so great\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from os import path\n",
    "AUDIO_FILE = \"audio.wav\"\n",
    "\n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(AUDIO_FILE) as source:\n",
    " audio1 = r.record(source) \n",
    "\n",
    "try:\n",
    "   print(\"Sphinx thinks you said \\n\" + r.recognize_sphinx(audio1))\n",
    "except sr.UnknownValueError:\n",
    "   print(\"Sphinx could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "  print(\"Sphinx error; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Recognition(male) with Sphinx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sphinx thinks you said \n",
      "what if somebody did that the break it be careful that you keep adequate coverage but look for places that they might it be it's taking longer to get the word away then the bankers expected hiring the lifer want company they wouldn't hurt badly that retirement and all the good help all but inadequate new told david broder early because of that in the cable when it that you can and do win the title of this type of targeting question you're a good line or waxman or getting the the paperweight my beeper smiled on bagwell clay is whether our place work on a flat surface and moved out that the blood then the peppered with the view that the angle of contained unit the old shop that it will hold a good mechanic acutely a bad bob hope the group would call her an eighty years some make beautiful chairs cabinet kept got called it that true\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from os import path\n",
    "AUDIO_FILE = \"male.wav\"\n",
    "\n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(AUDIO_FILE) as source:\n",
    " audio2 = r.record(source) \n",
    "\n",
    "try:\n",
    "   print(\"Sphinx thinks you said \\n\" + r.recognize_sphinx(audio2))\n",
    "except sr.UnknownValueError:\n",
    "   print(\"Sphinx could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "  print(\"Sphinx error; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Recognition(female) with Sphinx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sphinx thinks you said \n",
      "i had taken collectively aborigine hit bad and dignity can be untied threads of matches fifty feet in a choreographer met arbitrate he did not however fell back into acquiescence that that they were in baghdad in ad imagery and appalachian ironically and in the french them that personal birdcage were lecturing to advocated awful were under advisement any intercourse the rent and call it a he man apply encouraging that back and they'd be given your pride in it straight line with them alive that he needed the air quality in the brutality build small hole in bull with clay had multiple implications and comparable headache be marketed program them a bad headache initiative idea because the crooked overlapping twin and are widely they key do you always navigate like this\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from os import path\n",
    "AUDIO_FILE = \"female.wav\"\n",
    "\n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(AUDIO_FILE) as source:\n",
    " audio3 = r.record(source) \n",
    "\n",
    "try:\n",
    "   print(\"Sphinx thinks you said \\n\" + r.recognize_sphinx(audio3))\n",
    "except sr.UnknownValueError:\n",
    "   print(\"Sphinx could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "  print(\"Sphinx error; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Recognition(female) with Google API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Speech Recognition thinks you said \n",
      "this is what gives the operating in his are there of dignity turbulent towards roses much is 50 ft in a choreographer Mets arbitrate did not have ever settle back into acquiescence with things as they were around in this instance such personal virtues were a luxury few other cases offer under advisement Horsethief runs and edit multiple implications and possible headaches be a marketing program\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # for testing purposes, we're just using the default API key\n",
    "    # to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\n",
    "    # instead of `r.recognize_google(audio)`\n",
    "    print(\"Google Speech Recognition thinks you said \\n\" + r.recognize_google(audio3))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Recognition(korean) with Google API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 회사에 소문 다 났어요. 나랑 박동원이랑 그렇고 그런 사이라고, 사진도 찍혔고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T06:24:30.867231Z",
     "start_time": "2020-07-20T06:24:29.461678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Speech Recognition thinks you said \n",
      "회사에서 문 닫았어요 나랑 박동 우리랑 그렇고 그런 사이라고 사진도 찍혔고\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from os import path\n",
    "AUDIO_FILE = \"IU.wav\"\n",
    "\n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(AUDIO_FILE) as source:\n",
    " IU = r.record(source) \n",
    "\n",
    "try:\n",
    "    # for testing purposes, we're just using the default API key\n",
    "    # to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\n",
    "    # instead of `r.recognize_google(audio)`\n",
    "    print(\"Google Speech Recognition thinks you said \\n\" + r.recognize_google(IU, \n",
    "                                                            language='ko-KR'))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Recognition(korean) with Clova SCR API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T06:24:53.798059Z",
     "start_time": "2020-07-20T06:24:48.341475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clova Speech Recognition thinks you said \n",
      "\n",
      "\"회사에 소문이 다 났어요 나랑 박동훈이랑 그렇고 그런 사이라고 사준도 지켜\"}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import requests\n",
    "\n",
    "client_id = \"g2og1tquic\"\n",
    "client_secret = \"QHiQhaA3pOtRxSt5TMKlejCLH8kt4ccaYANgu7Rn\"\n",
    "lang = \"Kor\" # 언어 코드 ( Kor, Jpn, Eng, Chn )\n",
    "url = \"https://naveropenapi.apigw.ntruss.com/recog/v1/stt?lang=\" + lang\n",
    "data=open('IU.wav', 'rb')\n",
    "headers = {\n",
    "    \"X-NCP-APIGW-API-KEY-ID\": client_id,\n",
    "    \"X-NCP-APIGW-API-KEY\": client_secret,\n",
    "    \"Content-Type\": \"application/octet-stream\"\n",
    "}\n",
    "\n",
    "response = requests.post(url,  data=data, headers=headers)\n",
    "rescode = response.status_code\n",
    "if(rescode == 200):\n",
    "    print(\"Clova Speech Recognition thinks you said \\n\")\n",
    "    print (response.text[8:])\n",
    "else:\n",
    "    print(\"Error : \" + response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Recognition(korean) with ETRI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T06:29:48.920324Z",
     "start_time": "2020-07-20T06:29:44.951318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[responseCode] 200\n",
      "[responBody]\n",
      "{\"result\":0,\"return_object\":{\"recognized\":\"와 아아 아아 아아 \"}}\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "import json\n",
    "import base64\n",
    "openApiURL = \"http://aiopen.etri.re.kr:8000/WiseASR/Recognition\"\n",
    "accessKey = \"2964b17c-de50-465b-b181-a4f86ffb552b\"\n",
    "audioFilePath = \"IU2.wav\"\n",
    "languageCode = \"korean\"\n",
    "\n",
    "file = open(audioFilePath, \"rb\")\n",
    "audioContents = base64.b64encode(file.read()).decode(\"utf8\")\n",
    "file.close()\n",
    "\n",
    "requestJson = {\n",
    "    \"access_key\": accessKey,\n",
    "    \"argument\": {\n",
    "        \"language_code\": languageCode,\n",
    "        \"audio\": audioContents\n",
    "    }\n",
    "}\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "response = http.request(\n",
    "    \"POST\",\n",
    "    openApiURL,\n",
    "    headers={\"Content-Type\": \"application/json; charset=UTF-8\"},\n",
    "    body=json.dumps(requestJson)\n",
    ")\n",
    "\n",
    "print(\"[responseCode] \" + str(response.status))\n",
    "print(\"[responBody]\")\n",
    "print(str(response.data,\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T06:29:25.461490Z",
     "start_time": "2020-07-20T06:29:25.414001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='IU2.wav'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "AudioSegment.from_mp3(\"IU.wav\").export(\"IU2.wav\", format=\"wav\", bitrate=\"16k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "engine = pyttsx3.init() \n",
    "engine.say(\"Your Message\")\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_frame = pd.read_csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "woobin",
   "language": "python",
   "name": "woobin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
